{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training:\n",
    "\n",
    "Simple Train-Test Split (80-20%)  GA with k-fold (k=5).\n",
    "\n",
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Afra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stopit\\__init__.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Afra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:1230: FutureWarning: passing a class to None is deprecated and will be removed in 1.8. Use an instance of the class instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Afra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:1270: FutureWarning: passing a class to None is deprecated and will be removed in 1.8. Use an instance of the class instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n",
      "is_classifier\n",
      "is_regressor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf683330d454bb1afa0ee756a757ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.17254814224717033\n",
      "\n",
      "Generation 2 - Current best internal CV score: -0.1716133702600194\n",
      "\n",
      "Generation 3 - Current best internal CV score: -0.15770900961524725\n",
      "\n",
      "Generation 4 - Current best internal CV score: -0.15468028234920755\n",
      "\n",
      "Generation 5 - Current best internal CV score: -0.15468028234920755\n",
      "\n",
      "Generation 6 - Current best internal CV score: -0.1541718265524599\n",
      "\n",
      "Generation 7 - Current best internal CV score: -0.1541718265524599\n",
      "\n",
      "Generation 8 - Current best internal CV score: -0.1541718265524599\n",
      "\n",
      "Generation 9 - Current best internal CV score: -0.1541718265524599\n",
      "\n",
      "Generation 10 - Current best internal CV score: -0.1541718265524599\n",
      "\n",
      "Best pipeline: RandomForestRegressor(input_matrix, bootstrap=True, max_features=0.8, min_samples_leaf=3, min_samples_split=3, n_estimators=100)\n",
      "\n",
      "Best Model Details:\n",
      "Best Model: Pipeline(steps=[('randomforestregressor',\n",
      "                 RandomForestRegressor(max_features=0.8, min_samples_leaf=3,\n",
      "                                       min_samples_split=3, random_state=42))])\n",
      "Best Hyperparameters: {'memory': None, 'steps': [('randomforestregressor', RandomForestRegressor(max_features=0.8, min_samples_leaf=3, min_samples_split=3,\n",
      "                      random_state=42))], 'transform_input': None, 'verbose': False, 'randomforestregressor': RandomForestRegressor(max_features=0.8, min_samples_leaf=3, min_samples_split=3,\n",
      "                      random_state=42), 'randomforestregressor__bootstrap': True, 'randomforestregressor__ccp_alpha': 0.0, 'randomforestregressor__criterion': 'squared_error', 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 0.8, 'randomforestregressor__max_leaf_nodes': None, 'randomforestregressor__max_samples': None, 'randomforestregressor__min_impurity_decrease': 0.0, 'randomforestregressor__min_samples_leaf': 3, 'randomforestregressor__min_samples_split': 3, 'randomforestregressor__min_weight_fraction_leaf': 0.0, 'randomforestregressor__monotonic_cst': None, 'randomforestregressor__n_estimators': 100, 'randomforestregressor__n_jobs': None, 'randomforestregressor__oob_score': False, 'randomforestregressor__random_state': 42, 'randomforestregressor__verbose': 0, 'randomforestregressor__warm_start': False}\n",
      "Training MAE: 0.10807483221863437\n",
      "Test MAE: 0.160349096859056\n",
      "\n",
      "Optimization completed.\n",
      "Best model saved to 'best_model3.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tpot import TPOTRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_excel('Dataset_11_features.xlsx')\n",
    "\n",
    "# Prepare data\n",
    "X = df.drop(['NAM', 'REP', 'VAR', 'OLA', 'CT', 'CWC', 'WS', 'GW', 'PP', 'GP', 'GY', 'RS'], axis='columns')\n",
    "Y = df['OLA']\n",
    "\n",
    "# Standardize the features\n",
    "stdScale = StandardScaler().fit(X)\n",
    "X = stdScale.transform(X)\n",
    "\n",
    "# Split dataset into training (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize TPOTRegressor for hyperparameter optimization\n",
    "tpot = TPOTRegressor(\n",
    "    generations=10,  # Number of iterations\n",
    "    population_size=20,  # Number of models per generation\n",
    "    verbosity=2,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    random_state=42,\n",
    "    cv=5  # 5-fold cross-validation\n",
    ")\n",
    "\n",
    "# Fit TPOT to the training data\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_train = tpot.fitted_pipeline_.predict(X_train)\n",
    "y_pred_test = tpot.fitted_pipeline_.predict(X_test)\n",
    "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nBest Model Details:\")\n",
    "print(f\"Best Model: {tpot.fitted_pipeline_}\")\n",
    "print(f\"Best Hyperparameters: {tpot.fitted_pipeline_.get_params()}\")\n",
    "print(f\"Training MAE: {train_mae}\")\n",
    "print(f\"Test MAE: {test_mae}\")\n",
    "\n",
    "# Save the best model as a pickle file\n",
    "with open('best_model3.pkl', 'wb') as f:\n",
    "    pickle.dump(tpot.fitted_pipeline_, f)\n",
    "\n",
    "print(\"\\nOptimization completed.\")\n",
    "print(\"Best model saved to 'best_model3.pkl'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation of R² Score:\n",
    "\n",
    "R² ≈ 1 → Model predicts perfectly.\n",
    "\n",
    "R² > 0.8 → Strong prediction.\n",
    "\n",
    "R² ≈ 0.5-0.8 → Moderate prediction.\n",
    "\n",
    "R² < 0.5 → Weak prediction.\n",
    "\n",
    "R² < 0 → Model is worse than a simple average!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score of the Best Model: 0.9727\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the saved best model\n",
    "with open('best_model3.pkl', 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel('Dataset_11_features.xlsx')\n",
    "\n",
    "# Prepare data (same preprocessing as before)\n",
    "X = df.drop(['NAM', 'REP', 'VAR', 'OLA', 'CT', 'CWC', 'WS', 'GW', 'PP', 'GP', 'GY', 'RS'], axis='columns')\n",
    "Y = df['OLA']\n",
    "\n",
    "# Standardize the input features (same as in training)\n",
    "stdScale = StandardScaler().fit(X)\n",
    "X = stdScale.transform(X)\n",
    "\n",
    "# Make predictions using the best model\n",
    "Y_pred = best_model.predict(X)\n",
    "\n",
    "# Calculate R² score\n",
    "r2 = r2_score(Y, Y_pred)\n",
    "print(f\"R² Score of the Best Model: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.1589\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel('Dataset_11_features.xlsx')\n",
    "\n",
    "# Prepare data \n",
    "X = df.drop(['NAM', 'REP', 'VAR', 'OLA', 'CT', 'CWC', 'WS', 'GW', 'PP', 'GP', 'GY', 'RS'], axis='columns')\n",
    "Y = df['OLA']\n",
    "\n",
    "# Standardize the input features \n",
    "stdScale = StandardScaler().fit(X)\n",
    "X_scaled = stdScale.transform(X)\n",
    "\n",
    "# Suppress sklearn/version warnings \n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\") \n",
    "\n",
    "\n",
    "    # Load the saved best model \n",
    "    with open('best_model3.pkl', 'rb') as f:\n",
    "        best_model = pickle.load(f)\n",
    "\n",
    "    # Make predictions\n",
    "    Y_pred = best_model.predict(X_scaled)\n",
    "\n",
    "# Compute RMSE \n",
    "mse = mean_squared_error(Y, Y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"RMSE: {rmse:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
